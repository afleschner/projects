{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MjncuDf2qugI",
        "x9VSf2D_F5iU",
        "MzSKXh2LsOvd",
        "saFx1pbT_zTP",
        "5raTAgjNqRUF",
        "itoY9wsVkl33",
        "nElLJwarWjy6",
        "4k_50Wu_WwtD",
        "ocywoeAobtsW",
        "RvQ2D0Z_mQPP",
        "QXc40B0amUjc",
        "CWJmeKjPmbFe",
        "6-buwKTziQFM",
        "3t3QwyS6YsoC",
        "beneficial-bosnia",
        "I_st8oNN2HP4",
        "yEefF0r5ks5k",
        "6kkGKQNE0LLv",
        "8s_g9cbU0QG2",
        "je_A3rUm0Xn4",
        "vHhLpWuUjcmG",
        "QQK5fMh1wlAb",
        "7SSZaXjqCpJP",
        "m8abhixUwPD8"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjncuDf2qugI"
      },
      "source": [
        "## **Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9VSf2D_F5iU"
      },
      "source": [
        "### **Business Context**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dynamic landscape of the media and news industry, the ability to swiftly categorize and curate content has become a strategic imperative. The vast volume of information demands efficient systems to organize and present content to the audience.\n",
        "\n",
        "The media industry, being the pulse of information dissemination, grapples with the continuous influx of news articles spanning diverse topics. Ensuring that the right articles reach the right audience promptly is not just a logistical necessity but a critical component in retaining and engaging audiences in an age of information overload.\n",
        "\n",
        "Common Industry Challenges:\n",
        "Amidst the ceaseless flow of news, organizations encounter challenges such as:\n",
        "- Information Overload: The sheer volume of news articles makes manual categorization impractical.\n",
        "- Timeliness: Delays in categorizing news articles can result in outdated or misplaced content."
      ],
      "metadata": {
        "id": "RLApwDNbFDEK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzSKXh2LsOvd"
      },
      "source": [
        "### **Problem Definition**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E-news Express, a news aggregation startup, faces the challenge of categorizing the news articles collected. With news articles covering sports, busie=ness, politics, and more, the need for an advanced and automated system to categorize them has become increasingly evident. The manual efforts required for categorizing such a diverse range of news articles are substantial, and human errors in the categorization of news articles can lead to reputational damage for the startup. There is also the factor of delays and potential inaccuracies. To streamline and optimize this process, the organization recognizes the imperative of adopting cutting-edge technologies, particularly machine learning, to automate and enhance the categorization of content.\n",
        "\n",
        "As a data scientist on the E-news Express data team, the task is to analyze the text in news articles and build a model for categorizing them. The goal is to optimize the categorization process, ensuring timely and personalized delivery."
      ],
      "metadata": {
        "id": "PdEWl1qZFNWM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saFx1pbT_zTP"
      },
      "source": [
        "### **Data Dictionary**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Article**: The main body of the news article\n",
        "- **Category**: The category the article belongs to"
      ],
      "metadata": {
        "id": "5rJpifbLGVDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Please read the instructions carefully before starting the project.**\n",
        "\n",
        "This is a commented Python Notebook file in which all the instructions and tasks to be performed are mentioned.\n",
        "* Blanks '_______' are provided in the notebook that\n",
        "needs to be filled with an appropriate code to get the correct result. With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space.\n",
        "* Identify the task to be performed correctly, and only then proceed to write the required code.\n",
        "* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors.\n",
        "* Add the results/observations (wherever mentioned) derived from the analysis in the presentation and submit the same. Any mathematical or computational details which are a graded part of the project can be included in the Appendix section of the presentation.\n",
        "\n",
        "**Note**:\n",
        "1. Please make sure to use Google Colab for this project.\n",
        "2. It is recommended to use Colab's free GPU for this project.\n",
        "    - One can set the Colab runtime to ***T4 GPU*** before starting the project to use the GPU."
      ],
      "metadata": {
        "id": "yKWQVR9QVQdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installing and Importing Necessary Libraries and Dependencies**"
      ],
      "metadata": {
        "id": "5raTAgjNqRUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the libraries with the specified version.\n",
        "!pip install tensorflow==2.15.0 scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==1.5.3 torch==2.1.0+cu121 sentence-transformers==2.5.1 transformers==4.38.2 bitsandbytes==0.43.0 accelerate==0.27.2 sentencepiece==0.2.0 -q --user"
      ],
      "metadata": {
        "id": "H6f8pOi67VSf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**: If you encounter an error stating 'library not found,' please restart the kernel (do not disconnect the runtime) and try again."
      ],
      "metadata": {
        "id": "dPoWAe54IURt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, pipeline\n",
        "# To build a Random Forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# to split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# to compute performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,make_scorer,recall_score,precision_score,f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# to ignore unnecessary warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "ybNZns9tkLYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading the Dataset**"
      ],
      "metadata": {
        "id": "YvMxvNX4qZ94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NJOJLHXhMP3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the code to read the CSV file\n",
        "data = pd.read_csv(\"_____\")"
      ],
      "metadata": {
        "id": "HzzXmtWEmyr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Overview**"
      ],
      "metadata": {
        "id": "itoY9wsVkl33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the code to check the first 5 rows of the data\n"
      ],
      "metadata": {
        "id": "6y4fPeViVwrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the code to check the shape of the data\n"
      ],
      "metadata": {
        "id": "PyRd1ZMBVyC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to check the value counts in Category column\n",
        "data[\"______\"].value_counts()"
      ],
      "metadata": {
        "id": "tgyKktgDWG79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploratory Data Analysis (EDA)**\n"
      ],
      "metadata": {
        "id": "nElLJwarWjy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # function to create labeled barplots\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 1, 5))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 1, 5))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n].sort_values(),\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ],
      "metadata": {
        "id": "vtWvSKNFWosG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribution of category"
      ],
      "metadata": {
        "id": "4k_50Wu_WwtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data, \"_______\", perc=True)   ## Complete the code to get the barplot of Category variable"
      ],
      "metadata": {
        "id": "RmQ6xtEwW1do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Building - Sentence Transformer + ML**"
      ],
      "metadata": {
        "id": "ocywoeAobtsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the SentenceTransformer Model"
      ],
      "metadata": {
        "id": "RvQ2D0Z_mQPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining the model.\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "vlmPN7OemQPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_matrix_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    To plot the confusion_matrix with percentages\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(predictors)\n",
        "    cm = confusion_matrix(target, y_pred)\n",
        "    labels = np.asarray(\n",
        "        [\n",
        "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
        "            for item in cm.flatten()\n",
        "        ]\n",
        "    ).reshape(cm.shape[0], cm.shape[1])\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.xlabel(\"Predicted label\")"
      ],
      "metadata": {
        "id": "fVHCexiqcUCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding the data"
      ],
      "metadata": {
        "id": "QXc40B0amUjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the compute device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "## Encoding the dataset.\n",
        "embedding_matrix = model.encode(data[\"Article\"],show_progress_bar=True,device=device)"
      ],
      "metadata": {
        "id": "KySN6TJ8mUj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split"
      ],
      "metadata": {
        "id": "CWJmeKjPmbFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X = embedding_matrix\n",
        "y = data[\"Category\"]"
      ],
      "metadata": {
        "id": "q48zGQ2TmbF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial split into training (80%) and testing (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Further split the temporary set into validation (10%) and test (10%) sets\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)"
      ],
      "metadata": {
        "id": "6CtaZbkmmbGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the set of input variables for training:\", __________.shape)    # Complete the code to get the shape of training input data\n",
        "print(\"Shape of the set of input variables for validation:\", ________.shape)    # Complete the code to get the shape of validation input data\n",
        "print(\"Shape of the set of input variables for testing:\", __________.shape)     # Complete the code to get the shape of testing input data"
      ],
      "metadata": {
        "id": "4dC4m76iYsg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the set of output variables for training:\", __________.shape)    # Complete the code to get the shape of training output data\n",
        "print(\"Shape of the set of output variables for validation:\", ________.shape)    # Complete the code to get the shape of validation output data\n",
        "print(\"Shape of the set of output variables for testing:\", __________.shape)     # Complete the code to get the shape of testing output data"
      ],
      "metadata": {
        "id": "NE5tqfavYut5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-buwKTziQFM"
      },
      "source": [
        "### Random Forest Model (base)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
        "\n",
        "def model_performance_classification_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check classification model performance\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred,average=\"weighted\")  # to compute Recall\n",
        "    precision = precision_score(target, pred,average=\"weighted\")  # to compute Precision\n",
        "    f1 = f1_score(target, pred,average=\"weighted\")  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ],
      "metadata": {
        "id": "SPxZ4FjCnsHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44JGEAqS_lKj"
      },
      "outputs": [],
      "source": [
        "## Building the model\n",
        "rf = RandomForestClassifier(random_state = 42)\n",
        "\n",
        "## Compete the code to fit the model on X_train and y_train\n",
        "rf.fit(_______, _________)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "hXOCng1brwLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## To get the confusion matrix on X_train and y_train\n",
        "confusion_matrix_sklearn(rf, X_train, y_train)"
      ],
      "metadata": {
        "id": "pEIRHqZ-b6JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write the code to get the confusion matrix for X_valid and y_valid\n"
      ],
      "metadata": {
        "id": "Jgr_pa1yc9IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on train data\n",
        "y_pred_train = rf.predict(X_train)\n",
        "\n",
        "# Predicting on validation data\n",
        "y_pred_valid = rf.predict(X_valid)"
      ],
      "metadata": {
        "id": "vLqLtBfckP97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification report**"
      ],
      "metadata": {
        "id": "MpbPZz5g_lKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Classification report for train data\n",
        "print(classification_report(y_train, y_pred_train))"
      ],
      "metadata": {
        "id": "JTgU7xg3yzxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write the code to get the classification report for validation data\n"
      ],
      "metadata": {
        "id": "zu3KixgM_lKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Storing the metrics\n",
        "rf_train_perf = model_performance_classification_sklearn(\n",
        "    rf, X_train, y_train\n",
        ")"
      ],
      "metadata": {
        "id": "tFfXawi4n3Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Storing the metrics\n",
        "rf_valid_perf = model_performance_classification_sklearn(\n",
        "    rf, X_valid, y_valid\n",
        ")"
      ],
      "metadata": {
        "id": "YYIrmQpRn3n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t3QwyS6YsoC"
      },
      "source": [
        "### Random Forest (with class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GAdt6m6A73s"
      },
      "outputs": [],
      "source": [
        "## Building the model\n",
        "rf_balanced = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
        "\n",
        "## Complete the code to fit the model on X_train and y_train\n",
        "rf_balanced.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "YSSfwd3nr6HT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owKO5o68A73s"
      },
      "outputs": [],
      "source": [
        "## To get the confusion matrix on X_train and y_train\n",
        "confusion_matrix_sklearn(rf_balanced, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfcOiO7UA73s"
      },
      "outputs": [],
      "source": [
        "## Write the code to get the confusion matrix for X_valid and y_valid\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Predicting on train data\n",
        "y_pred_train = rf_balanced.predict(X_train)\n",
        "\n",
        "## Complete the code to predict the model on X_valid\n",
        "y_pred_valid = rf_balanced.predict(________)"
      ],
      "metadata": {
        "id": "M2iyVgEDfrQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification report**"
      ],
      "metadata": {
        "id": "CBMg0w5CfrQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Classification report for train data\n",
        "print(classification_report(y_train, y_pred_train))"
      ],
      "metadata": {
        "id": "0NwdQvVcfrQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write the code to get the classification report for validation data\n"
      ],
      "metadata": {
        "id": "e989l9YlfrQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Storing the metrics\n",
        "rf_bal_train_perf = model_performance_classification_sklearn(\n",
        "    rf_balanced, X_train, y_train\n",
        ")"
      ],
      "metadata": {
        "id": "5wKRaBrzn9i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to store the metrics of validation data\n",
        "rf_bal_valid_perf = model_performance_classification_sklearn(\n",
        "    rf_balanced, __________, ________\n",
        ")"
      ],
      "metadata": {
        "id": "iMnkVfwLn9-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beneficial-bosnia"
      },
      "source": [
        "### Random Forest (with hyperparamter tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interstate-jonathan"
      },
      "outputs": [],
      "source": [
        "## Building the model\n",
        "rf_tuned = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
        "\n",
        "## Defining the hyperparameter grid for tuning\n",
        "parameters = {\n",
        "    \"max_depth\": list(np.arange(4, 10, 3)),\n",
        "    \"max_features\": [\"sqrt\", 0.5, 0.7],\n",
        "    \"min_samples_split\": [5, 6],\n",
        "    \"n_estimators\": np.arange(30, 110, 15),\n",
        "}\n",
        "\n",
        "## Defining the type of scoring used to compare parameter combinations\n",
        "## We need to specify the mechanism of averaging as we have more than 2 target classes\n",
        "scorer = make_scorer(recall_score, average='weighted')\n",
        "\n",
        "## Running the grid search\n",
        "grid_obj = GridSearchCV(rf_tuned, parameters, scoring=scorer, cv=3, n_jobs=-1)\n",
        "\n",
        "## Complete the code to fit the model on X_train and y_train\n",
        "grid_obj = grid_obj.fit(_______, _________)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a new model with the best combination of parameters\n",
        "rf_tuned = grid_obj.best_estimator_\n",
        "\n",
        "## Complte the code to fit the new model to X_train and y_train\n",
        "rf_tuned.fit(________, _________)"
      ],
      "metadata": {
        "id": "ZRz5H6Dpe2bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joint-appendix"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "broadband-issue"
      },
      "outputs": [],
      "source": [
        "## Write the code to get the classification report for train data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "higher-memphis"
      },
      "outputs": [],
      "source": [
        "## Write the code to get the classification report for validation data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to predict the model on train data\n",
        "y_pred_train = rf_tuned.predict(_________)\n",
        "\n",
        "## Complete the code to predict the model on validation data\n",
        "y_pred_valid = rf_tuned.predict(__________)"
      ],
      "metadata": {
        "id": "XSPxEg33gl7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification report**"
      ],
      "metadata": {
        "id": "LrMNNFyigl7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write the code to get the classification report for train data\n"
      ],
      "metadata": {
        "id": "mbvdoRn2gl7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write the code to get the classification report for validation data\n"
      ],
      "metadata": {
        "id": "2fbJ4PJsgl7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to store the metrics of train data\n",
        "rf_tuned_train_perf = model_performance_classification_sklearn(\n",
        "    rf_tuned, _________, _______\n",
        ")"
      ],
      "metadata": {
        "id": "gyRDQGT9oAr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to store the metrics of validation data\n",
        "rf_tuned_valid_perf = model_performance_classification_sklearn(\n",
        "    rf_tuned, ______, ___________\n",
        ")"
      ],
      "metadata": {
        "id": "0eL1i6bBoClL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Building - Transformer**"
      ],
      "metadata": {
        "id": "I_st8oNN2HP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Target Mapping"
      ],
      "metadata": {
        "id": "yEefF0r5ks5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_map = {0:\"World\",1:\"Sports\",2:\"Business\",3:\"Sci/Tech\"}"
      ],
      "metadata": {
        "id": "HzOILnlinHKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_map"
      ],
      "metadata": {
        "id": "_Txb230RnYOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_class_map = {}\n",
        "for key,value in class_map.items():\n",
        "    reverse_class_map[value]=key\n",
        "\n",
        "reverse_class_map"
      ],
      "metadata": {
        "id": "lIp4YojsLTRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Tokenizer"
      ],
      "metadata": {
        "id": "6kkGKQNE0LLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Initializing a T5 tokenizer using the pre-trained model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")"
      ],
      "metadata": {
        "id": "VaC2NJ6YvUg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Model"
      ],
      "metadata": {
        "id": "8s_g9cbU0QG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Initializing a T5 model for conditional generation using the pre-trained model \"google/flan-t5-large\"\n",
        "\n",
        "# uncomment and use the following line in case GPU is not available\n",
        "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")\n",
        "\n",
        "# uncomment and use the following line in case GPU is available\n",
        "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\", load_in_8bit=True)"
      ],
      "metadata": {
        "id": "a-HHaUJpvW76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions for making predictions"
      ],
      "metadata": {
        "id": "je_A3rUm0Xn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining a function to compute different metrics.\n",
        "\n",
        "def model_performance_classification(pred, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check classification model performance\n",
        "\n",
        "    pred : prediction of the target variable.\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred,average=\"weighted\")  # to compute Recall\n",
        "    precision = precision_score(target, pred,average=\"weighted\")  # to compute Precision\n",
        "    f1 = f1_score(target, pred,average=\"weighted\")  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ],
      "metadata": {
        "id": "ZIooc_XuofI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a function to plot the confusion matrix\n",
        "def plot_confusion_matrix(actual, predicted):\n",
        "    cm = confusion_matrix(actual, predicted)\n",
        "\n",
        "    plt.figure(figsize = (5, 4))\n",
        "    label_list = ['World','Sports','Business','Sci/Tech']\n",
        "    sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = label_list, yticklabels = label_list)\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dA9rcByY2765"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to generate, process, and return a response\n",
        "def generate_response(prompt):\n",
        "    # uncomment and use the following line in case GPU is not available\n",
        "    # input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids    ### using the tokenizer to create tokens in tensor format from an input\n",
        "\n",
        "    # uncomment and use the following line in case GPU is available\n",
        "    # input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")    ### using the tokenizer to create tokens in tensor format from an input\n",
        "\n",
        "    outputs = model.generate(input_ids, max_length=16, do_sample=True, temperature=0.001)    ### generating the model output in tensor format\n",
        "    return tokenizer.decode(outputs[0])[6:-4]    ### using the tokenizer to decode the model output, and then return it"
      ],
      "metadata": {
        "id": "tg80Fp5jvYyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base Prompt for Prediction"
      ],
      "metadata": {
        "id": "vHhLpWuUjcmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Selecting and assigning specific columns\n",
        "X_train = data.iloc[y_train.index][\"Article\"]\n",
        "X_valid = data.iloc[y_test.index][\"Article\"]\n",
        "X_test = data.loc[y_valid.index][\"Article\"]"
      ],
      "metadata": {
        "id": "P_Xei8U52Qyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining a prompt which tells the model what to do\n",
        "sys_prompt = \"\"\"\n",
        "    <Write the instruction for the task here>\n",
        "\"\"\"\n",
        "\n",
        "## Predicting the category using the model by incorporating the system prompt and the provided review text\n",
        "\n",
        "pred_sent = generate_response(\n",
        "    \"\"\"\n",
        "        {}\n",
        "        news article: '{}'\n",
        "    \"\"\".format(sys_prompt, X_train[4])\n",
        ")\n",
        "\n",
        "print(pred_sent)"
      ],
      "metadata": {
        "id": "vtxgQ6qnveWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining a function to generate a sentiment prediction\n",
        "def predict_category(news_article):\n",
        "    pred = generate_response(\n",
        "        \"\"\"\n",
        "            {}\n",
        "            news article: '{}'\n",
        "        \"\"\".format(sys_prompt,news_article)\n",
        "    )\n",
        "\n",
        "    if \"Sports\" in pred:\n",
        "       pred=\"Sports\"\n",
        "    elif \"Business\" in pred:\n",
        "       pred=\"Business\"\n",
        "    elif \"World\" in pred:\n",
        "       pred=\"World\"\n",
        "    else:\n",
        "      pred=\"Sci/Tech\"\n",
        "\n",
        "    return reverse_class_map[pred]"
      ],
      "metadata": {
        "id": "L2L6MNlHv9hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Applying predict_category function on the train data\n",
        "y_pred_train_flan = X_train.apply(predict_category)"
      ],
      "metadata": {
        "id": "hp2vdp9H2dln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Applying predict_category function on the validation data\n",
        "y_pred_valid_flan = X_valid.apply(predict_category)"
      ],
      "metadata": {
        "id": "kPlelTW71BSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting the confusion matrix\n",
        "plot_confusion_matrix(y_train, y_pred_train_flan)"
      ],
      "metadata": {
        "id": "LSYdWY6v22Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to get the confusion matrix for validation data\n",
        "plot_confusion_matrix(__________, __________)"
      ],
      "metadata": {
        "id": "Of0t3mSz3van"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Getting the classification report for train data\n",
        "print(classification_report(y_train, y_pred_train_flan))"
      ],
      "metadata": {
        "id": "okrc29PR37Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to get the classification report for validation data\n",
        "print(classification_report(__________, __________))"
      ],
      "metadata": {
        "id": "hY7jvYrc38pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Storing the metrics\n",
        "flan_train_base = model_performance_classification(y_pred_train_flan,y_train)\n",
        "flan_valid_base = model_performance_classification(y_pred_valid_flan,y_valid)"
      ],
      "metadata": {
        "id": "RnPDOUXHo-Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improved Prompt for Prediction"
      ],
      "metadata": {
        "id": "QQK5fMh1wlAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a prompt which tells the model what to do\n",
        "sys_prompt = \"\"\"\n",
        "    <Write the instruction for the task here>\n",
        "    <This prompt will be an improved version of the previous prompt to improve model performance>\n",
        "\"\"\"\n",
        "\n",
        "# predicting the sentiment using the model by incorporating the system prompt and the provided review text\n",
        "\n",
        "pred_sent = generate_response(\n",
        "    \"\"\"\n",
        "        {}\n",
        "        news article: '{}'\n",
        "    \"\"\".format(sys_prompt, X[4])\n",
        ")\n",
        "\n",
        "print(pred_sent)"
      ],
      "metadata": {
        "id": "SXFIKi2WnD5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Applying predict_category function on the train data\n",
        "y_pred_train_flan_imp = X_train.apply(predict_category)"
      ],
      "metadata": {
        "id": "5TPLg0BvnI68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Applying predict_category function on the validation data\n",
        "y_pred_valid_flan_imp = X_valid.apply(predict_category)"
      ],
      "metadata": {
        "id": "7LgX429u1PBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting the confusion matrix for train data\n",
        "plot_confusion_matrix(y_train, y_pred_train_flan_imp)"
      ],
      "metadata": {
        "id": "1XhggCNBnNXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the codet to get the confusion matrix for validation data\n",
        "plot_confusion_matrix(______, _______)"
      ],
      "metadata": {
        "id": "ga0M5ozNnVfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Getting the classification report for train data\n",
        "print(classification_report(y_train, y_pred_train_flan_imp))"
      ],
      "metadata": {
        "id": "BTZJ8nyonUCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to get the classification report for validation data\n",
        "print(classification_report(__________, __________))"
      ],
      "metadata": {
        "id": "bI-ZzHmxnW9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Storing the metrics\n",
        "flan_train_imp = model_performance_classification(y_pred_train_flan_imp,y_train)\n",
        "flan_valid_imp = model_performance_classification(y_pred_valid_flan_imp,y_valid)"
      ],
      "metadata": {
        "id": "yqZa5mJRpLpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Performance Comparison and Final Model Selection**"
      ],
      "metadata": {
        "id": "7SSZaXjqCpJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Training performance comparison\n",
        "\n",
        "models_train_comp_df = pd.concat(\n",
        "    [\n",
        "        rf_train_perf.T,\n",
        "        rf_bal_train_perf.T,\n",
        "        rf_tuned_train_perf.T,\n",
        "        flan_train_base.T,\n",
        "        flan_train_imp.T\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "models_train_comp_df.columns = [\n",
        "    \"Random Forest(base)\",\n",
        "    \"Random Forest with class_weights\",\n",
        "    \"Random Forest(tuned)\",\n",
        "    \"Flan (base prompt)\",\n",
        "    \"Flan (improvised prompt)\"\n",
        "]\n",
        "print(\"Training performance comparison:\")\n",
        "models_train_comp_df"
      ],
      "metadata": {
        "id": "n7Ccm3EzoGBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Validation set performance comparison\n",
        "models_valid_comp_df = pd.concat(\n",
        "    [\n",
        "        rf_valid_perf.T,\n",
        "        rf_bal_valid_perf.T,\n",
        "        rf_tuned_valid_perf.T,\n",
        "        flan_valid_base.T,\n",
        "        flan_valid_imp.T\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "models_valid_comp_df.columns = [\n",
        "    \"Random Forest(base)\",\n",
        "    \"Random Forest with class_weights\",\n",
        "    \"Random Forest(tuned)\",\n",
        "    \"Flan (base prompt)\",\n",
        "    \"Flan (improvised prompt)\"\n",
        "]\n",
        "print(\"Validation set performance comparison:\")\n",
        "models_valid_comp_df"
      ],
      "metadata": {
        "id": "P9DkazaYoG7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pick the best model from the above table and apply on test data**"
      ],
      "metadata": {
        "id": "aFl_nDjydkIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Assigns test rows based on index\n",
        "X_test = embedding_matrix[y_test.index]"
      ],
      "metadata": {
        "id": "6Ssv5-OfB3wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix_sklearn(rf_balanced, X_test, y_test))"
      ],
      "metadata": {
        "id": "Al2BWSBoCpJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on test data\n",
        "y_pred_test = rf_balanced.predict(X_test)"
      ],
      "metadata": {
        "id": "0XgD6eAbCpJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "PMDmSUlJCpJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Actionable Insights and Recommendations**"
      ],
      "metadata": {
        "id": "m8abhixUwPD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-\n",
        "\n"
      ],
      "metadata": {
        "id": "ceLY_cMcyds1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gDuzgE_myXEC"
      }
    }
  ]
}